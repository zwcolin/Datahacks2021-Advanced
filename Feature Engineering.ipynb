{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('datasets/viz_eda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw.pivot(index = \"date\", columns = \"series_id\", values = \"value\")\n",
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-oxford",
   "metadata": {},
   "source": [
    "## Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for g in raw.groupby(\"series_id\"):\n",
    "    tmp = g[1]\n",
    "    tmp[\"diff\"] = tmp[\"value\"].diff()\n",
    "    tmp = tmp.drop(columns = \"value\")\n",
    "    ls.append(tmp.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = pd.concat(ls).dropna().pivot(index = \"date\", columns = \"series_id\", values = \"diff\").drop(columns = \"SP500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = diff.fillna(method = \"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-socket",
   "metadata": {},
   "source": [
    "## Technical Indecator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_technical(sp500):\n",
    "    tech = sp500.copy()\n",
    "    tech['ma7'] = tech[\"SP500\"].rolling(7).mean()\n",
    "    tech['ma21'] = tech[\"SP500\"].rolling(21).mean()\n",
    "    tech['26ema'] = tech[\"SP500\"].ewm(span=26).mean()\n",
    "    tech['12ema'] = tech[\"SP500\"].ewm(span=12).mean()\n",
    "    tech['MACD'] = (tech['12ema']-tech['26ema'])\n",
    "    tech['20sd'] = tech[\"SP500\"].rolling(20).std()\n",
    "    tech['upper_band'] = tech['ma21'] + (tech['20sd']*2)\n",
    "    tech['lower_band'] = tech['ma21'] - (tech['20sd']*2)\n",
    "    tech['ema'] = tech[\"SP500\"].ewm(com=0.5).mean()\n",
    "    tech['momentum'] = tech[\"SP500\"].diff()\n",
    "    tech = tech.drop(columns = \"SP500\").shift(periods=1)\n",
    "    tech[\"value\"] = sp500[\"SP500\"]\n",
    "    return tech[[\"ma7\",\"ma21\",\"26ema\",\"12ema\",\"MACD\",\"ema\",\"momentum\",\"upper_band\", \"lower_band\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"datasets/observations_train.csv\")\n",
    "train = train[train[\"series_id\"] == \"SP500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"datasets/observations_test.csv\")\n",
    "test = test[test[\"series_id\"] == \"SP500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([train,test])\n",
    "merged = merged.pivot(index = \"date\", columns = \"series_id\", values = \"value\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.index = merged.index.map(lambda x:x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = get_technical(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech.to_csv(\"datasets/technical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = (tech - tech.mean()) / tech.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-roman",
   "metadata": {},
   "source": [
    "## Fourier transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from numpy import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourierExtrapolation(x, n_predict, n_harm):\n",
    "    n = x.size            \n",
    "    t = np.arange(0, n)\n",
    "    p = np.polyfit(t, x, 1)         # find linear trend in x\n",
    "    x_notrend = x - p[0] * t        # detrended x\n",
    "    x_freqdom = fft.fft(x_notrend)  # detrended x in frequency domain\n",
    "    f = fft.fftfreq(n)              # frequencies\n",
    "    indexes = list(range(n))\n",
    "    # sort indexes by frequency, lower -> higher\n",
    "    indexes.sort(key = lambda i: np.absolute(f[i]))\n",
    " \n",
    "    t = np.arange(0, n + n_predict)\n",
    "    restored_sig = np.zeros(t.size)\n",
    "    for i in indexes[:1 + n_harm * 2]:\n",
    "        ampli = np.absolute(x_freqdom[i]) / n   # amplitude\n",
    "        phase = np.angle(x_freqdom[i])          # phase\n",
    "        restored_sig += ampli * np.cos(2 * np.pi * f[i] * t + phase)\n",
    "    return restored_sig + p[0] * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "for harm in [3,5,10,100]:\n",
    "    pred = []\n",
    "    for i in range(2,len(merged)):\n",
    "        pred.append(fourierExtrapolation(merged.values[max(0,i - 1000) :i,0],1, harm)[-1])\n",
    "    ft[\"ft\" + str(harm)] = [np.NaN,np.NaN] + pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.tail(500).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.to_csv(\"datasets/FT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = (ft - ft.mean())/ ft.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-dinner",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "doy = pd.to_datetime(df.index.values).dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SIN_DATE'] = np.sin(2*np.pi*doy/365)\n",
    "df['COS_DATE'] = np.cos(2*np.pi*doy/365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-disaster",
   "metadata": {},
   "source": [
    "## Merge Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(ft.drop(columns = \"SP500\"), how = \"left\", left_index=True, right_index=True)\n",
    "df = df.merge(tech, how = \"left\", left_index=True, right_index=True)\n",
    "df = df.merge(merged, how = \"left\", left_index=True, right_index=True)\n",
    "df = df.merge(diff, how = \"left\", suffixes = [None, \"_DIFF\"], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"all_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
