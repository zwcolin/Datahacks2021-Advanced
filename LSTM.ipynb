{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout,TimeDistributed, Conv1D, MaxPooling1D, Flatten, Reshape, GRU\n",
    "from keras.regularizers import l2\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-plate",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-experience",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"datasets/all_features.csv\")\n",
    "raw = raw.drop(columns = [\"SOFR\",\"SOFRVOL\",\"EFFRVOL\",\"OBFR\",\"OBFRVOL\",\"EFFRVOL_DIFF\"\n",
    "                          ,\"OBFR_DIFF\",\"OBFRVOL_DIFF\",\"SP500_UNNORM\", \"SOFR_DIFF\", \"SOFRVOL_DIFF\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-commander",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = raw[raw[\"date\"] < \"2018-00-00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = raw[raw[\"date\"] > \"2018-00-00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-template",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"datasets/train.csv\")\n",
    "test.to_csv(\"datasets/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns = [\"SP500_NORM\", \"date\"]).values\n",
    "y_train = train[\"SP500_NORM\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns = [\"SP500_NORM\", \"date\"]).values\n",
    "y_test = test[\"SP500_NORM\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(X, y, n_steps):\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "    for i in range(0, len(X)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps - 1\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(X)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = X[i:end_ix+1], (y[end_ix] - y[end_ix - 1])\n",
    "        new_y.append(seq_y)\n",
    "        new_X.append(seq_x)\n",
    "    return array(new_X), array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_stats(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-penguin",
   "metadata": {},
   "source": [
    "## LSTM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 365\n",
    "lstm_size = 200\n",
    "weight_decay = 1e-3\n",
    "lr = 1e-4\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_splited, y_train_splited = split_sequence(X_train, y_train, n_steps)\n",
    "X_test_splited, y_test_splited = split_sequence(X_test, y_test, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-dealing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024))\n",
    "model.add(LSTM(lstm_size, activation='relu', input_shape=(n_steps, n_features), return_sequences=True,\n",
    "               kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "               bias_regularizer=l2(weight_decay)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay)))\n",
    "model.add(Dense(16, kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay)))\n",
    "model.add(Dense(1, kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay), activation = \"tanh\"))\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(opt, loss='mse')\n",
    "# fit model\n",
    "history = model.fit(X_train_splited, y_train_splited,\n",
    "          epochs=epochs,  batch_size=64, shuffle=True,\n",
    "          validation_data=(X_test_splited, y_test_splited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_stats(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-dining",
   "metadata": {},
   "source": [
    "## Stacked LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 30\n",
    "lstm_size = 200\n",
    "weight_decay = 1e-2\n",
    "lr = 1e-4\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape = (20,50)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-multiple",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train_splited, y_train_splited,\n",
    "          epochs=epochs,  batch_size=64, shuffle=True,\n",
    "          validation_data=(X_test_splited, y_test_splited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_stats(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-transsexual",
   "metadata": {},
   "source": [
    "## Conv LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Reshape((-1,1)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_splited, y_train_splited,\n",
    "          epochs=epochs,  batch_size=64, shuffle=True,\n",
    "          validation_data=(X_test_splited, y_test_splited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_stats(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-preserve",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=50, return_sequences=True, input_shape=(n_steps,n_features), activation='tanh',\n",
    "              kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=50, return_sequences=True, input_shape=(n_steps,n_features), activation='tanh',\n",
    "              kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=50, return_sequences=True, input_shape=(n_steps,n_features), activation='tanh',\n",
    "              kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=50, activation='tanh', return_sequences=False,\n",
    "             kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1,kernel_regularizer=l2(weight_decay) ))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-carry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train_splited, y_train_splited,\n",
    "          epochs=5,  batch_size=64, shuffle=True,\n",
    "          validation_data=(X_test_splited, y_test_splited))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
