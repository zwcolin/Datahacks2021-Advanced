{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "median-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extensive-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('datasets/series.csv', encoding= 'unicode_escape')\n",
    "train = pd.read_csv('datasets/observations_train.csv')\n",
    "test = pd.read_csv('datasets/observations_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accessible-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct datatype\n",
    "train.date = pd.to_datetime(train.date)\n",
    "test.date = pd.to_datetime(test.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forty-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include sp500 which has 'Daily, Close'\n",
    "daily_id = series[(series.frequency == 'Daily') | (series.frequency == 'Daily, 7-Day') |\\\n",
    "                  (series.frequency == 'Daily, Close')]['ï»¿series_id']\n",
    "weekly_id = series[(series.frequency == 'Weekly, Ending Saturday') | (series.frequency == 'Weekly, Ending Thursday') |\\\n",
    "                   (series.frequency == 'Weekly, Ending Wednesday')]['ï»¿series_id']\n",
    "monthly_id = series[(series.frequency == 'Monthly')]['ï»¿series_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cellular-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data and exclude weekends\n",
    "train_daily = train[train['series_id'].isin(daily_id)]\n",
    "train_weekly = train[train['series_id'].isin(weekly_id)]\n",
    "train_monthly = train[train['series_id'].isin(monthly_id)]\n",
    "train_daily = train_daily[train_daily['date'].dt.dayofweek < 5]\n",
    "\n",
    "test_daily = test[test['series_id'].isin(daily_id)]\n",
    "test_weekly = test[test['series_id'].isin(weekly_id)]\n",
    "test_monthly = test[test['series_id'].isin(monthly_id)]\n",
    "test_daily = test_daily[test_daily['date'].dt.dayofweek < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alternative-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index for date\n",
    "for df in [train_daily, train_weekly, train_monthly, test_daily, test_weekly, test_monthly]:\n",
    "    df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "taken-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a total of 1 na in train ser after interpolation\n",
    "train_daily = train_daily.groupby('series_id').apply(lambda group: group.interpolate('time')).dropna()\n",
    "train_weekly = train_weekly.groupby('series_id').apply(lambda group: group.interpolate('time'))\n",
    "train_monthly = train_monthly.groupby('series_id').apply(lambda group: group.interpolate('time'))\n",
    "\n",
    "# a total of 0 na in train ser after interpolation\n",
    "test_daily = test_daily.groupby('series_id').apply(lambda group: group.interpolate('time'))\n",
    "test_weekly = test_weekly.groupby('series_id').apply(lambda group: group.interpolate('time'))\n",
    "test_monthly = test_monthly.groupby('series_id').apply(lambda group: group.interpolate('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "informational-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = pd.concat([train_daily, test_daily])\n",
    "weekly = pd.concat([train_weekly, test_weekly])\n",
    "monthly = pd.concat([train_monthly, test_monthly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "identical-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return normalized dataset and stats to unnormalize\n",
    "def in_group_norm(df):\n",
    "    stats = pd.DataFrame()\n",
    "    stats['series_id'] = df.series_id.unique().tolist()\n",
    "    stats['mean'] = df.groupby('series_id').mean().value.tolist()\n",
    "    stats['std'] = df.groupby('series_id').std().value.tolist()\n",
    "    df.value = df.groupby('series_id').transform(lambda x: (x - x.mean()) / x.std()).value\n",
    "    return df, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hawaiian-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily, daily_stats = in_group_norm(daily)\n",
    "weekly, weekly_stats = in_group_norm(weekly)\n",
    "monthly, monthly_stats = in_group_norm(monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_daily, train_daily_stats = in_group_norm(train_daily)\n",
    "train_weekly, train_weekly_stats = in_group_norm(train_weekly)\n",
    "train_monthly, train_monthly_stats = in_group_norm(train_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accredited-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "train_daily, train_daily_stats = in_group_norm(train_daily)\n",
    "train_weekly, train_weekly_stats = in_group_norm(train_weekly)\n",
    "train_monthly, train_monthly_stats = in_group_norm(train_monthly)\n",
    "\n",
    "test_daily, test_daily_stats = in_group_norm(test_daily)\n",
    "test_weekly, test_weekly_stats = in_group_norm(test_weekly)\n",
    "test_monthly, test_monthly_stats = in_group_norm(test_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "developmental-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat back to train and test set\n",
    "train_cleaned = pd.concat([train_daily, train_weekly, train_monthly])\n",
    "test_cleaned = pd.concat([test_daily, test_weekly, test_monthly])\n",
    "\n",
    "train_cleaned.to_csv('datasets/train_cleaned.csv')\n",
    "test_cleaned.to_csv('datasets/test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "super-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([daily, weekly, monthly]).to_csv('datasets/viz_eda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "intense-psychology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-12-01</th>\n",
       "      <td>ASEANTOT</td>\n",
       "      <td>0.170858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>ASEANTOT</td>\n",
       "      <td>0.105568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-01</th>\n",
       "      <td>ASEANTOT</td>\n",
       "      <td>-0.122946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-01</th>\n",
       "      <td>ASEANTOT</td>\n",
       "      <td>-0.057656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-01</th>\n",
       "      <td>ASEANTOT</td>\n",
       "      <td>-0.090301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>-1.268090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>-1.215389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>-1.268090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>-0.793781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>4.634418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7767 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           series_id     value\n",
       "date                          \n",
       "2003-12-01  ASEANTOT  0.170858\n",
       "2004-01-01  ASEANTOT  0.105568\n",
       "2004-02-01  ASEANTOT -0.122946\n",
       "2004-03-01  ASEANTOT -0.057656\n",
       "2004-04-01  ASEANTOT -0.090301\n",
       "...              ...       ...\n",
       "2019-12-01    UNRATE -1.268090\n",
       "2020-01-01    UNRATE -1.215389\n",
       "2020-02-01    UNRATE -1.268090\n",
       "2020-03-01    UNRATE -0.793781\n",
       "2020-04-01    UNRATE  4.634418\n",
       "\n",
       "[7767 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-rendering",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
